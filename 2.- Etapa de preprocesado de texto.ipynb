{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWgh2birYK_j"
   },
   "source": [
    "# Etapa de preprocesado de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VxActA0CYGtU"
   },
   "outputs": [],
   "source": [
    "#Librerias:\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5fFFCzK2Yehh"
   },
   "outputs": [],
   "source": [
    "#Cargar dataset:\n",
    "df = pd.read_csv('/content/sampled_data_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0pm0f3lbdy0",
    "outputId": "6403fc89-3751-41af-e3ce-3a6964213027"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#Descargar la lista de palabras vacías:\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords = set(stopwords) - set(['not', 'no', 'nor', 'but'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HPC1izqcDK1",
    "outputId": "61a45eed-3cae-4890-bab0-a789b0b30c05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Descarga el recurso punkt:\n",
    "nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PwJWZy-cqVJ",
    "outputId": "a2d38c98-3c3f-42b8-89d7-52e1f7e8f30d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "#Descargar la base de datos de WordNet:\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "#Crear el lematizador: \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8GNqFQL4ZD0H"
   },
   "outputs": [],
   "source": [
    "#Crear la función para preprocesar el texto:\n",
    "\n",
    "def preprocess(text):\n",
    "  #Obtener todo el texto en minúsculas:\n",
    "  text = text.lower()\n",
    "  #Eliminar puntuación: \n",
    "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "  #tokenizar el texto:\n",
    "  text = nltk.word_tokenize(text)\n",
    "  #Eliminar palabras vacías:\n",
    "  text =  [word for word in text if word not in stopwords]\n",
    "  #lematizar el texto: \n",
    "  text = [lemmatizer.lemmatize(token) for token in text]\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "y_DAgN_fgJV-",
    "outputId": "ed9fcbf7-bc69-4671-baf6-65fb5a3d1687"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This is a pretty good game! My daughter loves all the different unique features that it offers. I gave it four stars because of the acting feature. This was the main reason why we got it since she loves acting. Well they do not offer much variety on this feature. Pretty much all your doing is posing rather than acting! But other than that, it was okay all around.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vq9UYJyqdE1f",
    "outputId": "bed945ce-d679-47b9-a3ee-cd292a76156e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pretty',\n",
       " 'good',\n",
       " 'game',\n",
       " 'daughter',\n",
       " 'love',\n",
       " 'different',\n",
       " 'unique',\n",
       " 'feature',\n",
       " 'offer',\n",
       " 'gave',\n",
       " 'four',\n",
       " 'star',\n",
       " 'acting',\n",
       " 'feature',\n",
       " 'main',\n",
       " 'reason',\n",
       " 'got',\n",
       " 'since',\n",
       " 'love',\n",
       " 'acting',\n",
       " 'well',\n",
       " 'not',\n",
       " 'offer',\n",
       " 'much',\n",
       " 'variety',\n",
       " 'feature',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'posing',\n",
       " 'rather',\n",
       " 'acting',\n",
       " 'but',\n",
       " 'okay',\n",
       " 'around']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = df['reviewText'][0]\n",
    "preprocess(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sX0OzPDggit_"
   },
   "outputs": [],
   "source": [
    "#Aplicar el preproceso en los datos:\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GWWbtoYvgxno"
   },
   "outputs": [],
   "source": [
    "#Crear nuevo csv con el texto preprocesado, limitado al texto y a las reseñas:\n",
    "df_preprocessed = df[['overall', 'reviewText']]\n",
    "df_preprocessed.to_csv('final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "279e41f851e3a758ad70de47b59217a5307449cfb5bf9da795e3f338ef26c0e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
